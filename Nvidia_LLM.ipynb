{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b78f34b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"NVIDIA'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" LLM oroject By Amr El Eisawi\"\"\"\n",
    "\"\"\"\"NVIDIA\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4e9ead",
   "metadata": {},
   "source": [
    "Libary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b202001a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import requests\n",
    "import gradio as gr\n",
    "\n",
    "from fastapi import FastAPI, UploadFile, File\n",
    "import uvicorn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01aeaede",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, Docx2txtLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ac43b2",
   "metadata": {},
   "source": [
    "CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944b4722",
   "metadata": {},
   "source": [
    "LLM API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1354e36",
   "metadata": {},
   "source": [
    "INGESTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "589f622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "MODEL_NAME = \"gemma3:4b\" \n",
    "\n",
    "def ask_llm(messages):\n",
    "    \"\"\"\n",
    "    Convert messages to prompt and ask Ollama model locally.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        prompt = \"\\n\".join(f\"{msg['role']}: {msg['content']}\" for msg in messages)\n",
    "\n",
    "        # استدعاء الموديل المحلي\n",
    "        response = ollama.chat(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "\n",
    "        return response['message']['content']\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"LLM Error: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9570ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents(path: str):\n",
    "    if path.endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(path)\n",
    "    elif path.endswith(\".docx\"):\n",
    "        loader = Docx2txtLoader(path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")\n",
    "    return loader.load()\n",
    "\n",
    "\n",
    "def create_vectorstore(file_path: str):\n",
    "    docs = load_documents(file_path)\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=900,\n",
    "        chunk_overlap=150\n",
    "    )\n",
    "\n",
    "    chunks = splitter.split_documents(docs)\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "    vs = FAISS.from_documents(chunks, embeddings)\n",
    "    vs.save_local(INDEX_PATH)\n",
    "    return vs\n",
    "\n",
    "\n",
    "def load_vectorstore():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return FAISS.load_local(\n",
    "        INDEX_PATH,\n",
    "        embeddings,\n",
    "        allow_dangerous_deserialization=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67068020",
   "metadata": {},
   "source": [
    "MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab46f370",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_store = []\n",
    "\n",
    "def add_to_history(q, a):\n",
    "    history_store.append({\"q\": q, \"a\": a})\n",
    "\n",
    "def get_history():\n",
    "    return history_store[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c50c4b6",
   "metadata": {},
   "source": [
    "RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57bdbf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = None\n",
    "\n",
    "def ask_question(question: str):\n",
    "    global vectorstore\n",
    "\n",
    "    if vectorstore is None:\n",
    "        return \" Upload a document first.\", []\n",
    "\n",
    "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "    docs = retriever.invoke(question)\n",
    "\n",
    "    if not docs:\n",
    "        return \"I couldn't find relevant information in the document.\", []\n",
    "\n",
    "    context = \"\\n\\n\".join([d.page_content for d in docs])\n",
    "    citations = [f\"Page {d.metadata.get('page', '?')}\" for d in docs]\n",
    "\n",
    "    history = get_history()\n",
    "    history_text = \"\\n\".join([f\"Q: {h['q']} A: {h['a']}\" for h in history])\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": (\n",
    "                \"You are a legal assistant. Use the context provided to answer questions thoroughly. \"\n",
    "                \"Be concise but complete. If information is not in the context, say so explicitly.\\n\\n\"\n",
    "                f\"Conversation History:\\n{history_text}\\n\\n\"\n",
    "                f\"Context:\\n{context}\"\n",
    "            )\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "\n",
    "    answer = ask_llm(messages)\n",
    "    add_to_history(question, answer)\n",
    "\n",
    "    return answer, citations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5e4c2f",
   "metadata": {},
   "source": [
    "API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c0ca34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = FastAPI(title=\"Smart Contract Assistant\")\n",
    "\n",
    "@app.post(\"/upload\")\n",
    "async def upload_contract(file: UploadFile = File(...)):\n",
    "    global vectorstore\n",
    "\n",
    "    path = f\"temp_{file.filename}\"\n",
    "    with open(path, \"wb\") as buffer:\n",
    "        shutil.copyfileobj(file.file, buffer)\n",
    "\n",
    "    try:\n",
    "        vectorstore = create_vectorstore(path)\n",
    "        return {\"status\": \"indexed\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Failed to index document: {str(e)}\"}\n",
    "\n",
    "\n",
    "@app.post(\"/chat\")\n",
    "async def chat_api(q: str):\n",
    "    answer, sources = ask_question(q)\n",
    "    return {\"answer\": answer, \"sources\": sources}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc0ed715",
   "metadata": {},
   "outputs": [],
   "source": [
    "API = \"http://localhost:8000\"\n",
    "\n",
    "def upload_ui(file):\n",
    "    files = {\"file\": (file.name, open(file.name, \"rb\"))}\n",
    "    r = requests.post(f\"{API}/upload\", files=files)\n",
    "    if r.status_code == 200:\n",
    "        return r.json()\n",
    "    else:\n",
    "        return {\"error\": f\"Upload failed: {r.status_code} - {r.text}\"}\n",
    "\n",
    "def chat_ui(message, history):\n",
    "    r = requests.post(f\"{API}/chat\", params={\"q\": message})\n",
    "    if r.status_code == 200:\n",
    "        data = r.json()\n",
    "        reply = data[\"answer\"]\n",
    "        sources = \", \".join(data[\"sources\"])\n",
    "        if sources:\n",
    "            reply += f\" Sources: {sources}\"\n",
    "        history.append({\"role\": \"user\", \"content\": message})\n",
    "        history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "        return history, history\n",
    "    else:\n",
    "        error_msg = f\"Chat failed: {r.status_code} - {r.text}\"\n",
    "        history.append({\"role\": \"user\", \"content\": message})\n",
    "        history.append({\"role\": \"assistant\", \"content\": error_msg})\n",
    "        return history, history\n",
    "\n",
    "\n",
    "def launch_ui():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\" Smart Contract Assistant\")\n",
    "\n",
    "        with gr.Tab(\"Upload\"):\n",
    "            file = gr.File()\n",
    "            out = gr.JSON()\n",
    "            btn = gr.Button(\"Upload & Index\")\n",
    "            btn.click(upload_ui, file, out)\n",
    "\n",
    "        with gr.Tab(\"Chat\"):\n",
    "            chatbot = gr.Chatbot()\n",
    "            msg = gr.Textbox()\n",
    "            msg.submit(chat_ui, [msg, chatbot], [chatbot, chatbot])\n",
    "\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d420e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    import threading\n",
    "\n",
    "    def run_api():\n",
    "        uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "\n",
    "    threading.Thread(target=run_api).start()\n",
    "    launch_ui()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
